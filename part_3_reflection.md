For my project, I wanted to analyze two Shakespeare plays. The two plays I chose are The Tragedy of Hamlet and The Tragedy of Macbeth. This is because these are two plays I studied in high school on a literal method, but I never had the opportunity to analyze the text in a more qualitative way. I found the two plays in text from Project Gutenberg and downloaded the two texts onto my resp. From this project, I wanted to see if there are many similarities between the two plays, as they are both tragedy plays written by if not the most famous play writer Shakespeare. 

The first part of my project focuses on importing the plays into my data files in github and performing data cleaning. Next I did text analysis to see same interesting facts about the plays. This includes how many words are in the play, and the number of unique words. I also compared the most common words from the two plays with each other. Lasty, I did a sentiment analysis and fuzz analysis on the play. For the number of unique words, because there were many similarities between the two plays, originally only using the top 10 most frequent was not enough. Because of this, I added the range on the functions to increase the number of most common words considered for the comparison to show adequate result. Then, I realised that the problem was not with the range, but rather too many stopwords. I added a function to remove the stopwords to get a more accurate result.

looking at the basic of the text, Hamlet is a longer play compared to Macbeth. This shows as there are 29703 words and 4808 unique words in Hamlet, compared to 17829 words and 3550 unique words in Macbeth.

I think the most interesting finding about the two plays is that there are a lot of common words in both plays. I did expect to find common words, but not the the extend of the top 5 most frequent words for the two plays are the same. The top 10 most common words in hamlet and macbeth are [the, and, to, of, i]. This shows that even though the two plays are different, because they are both writtin by shakespeare, similar writtin style is used with preferences for some words over others. After realising that these are all stopwords, I wrote a new function to remove the stopwords to get a better idea of the most common words from the plays. The most common word from Hamlet is ham and lord, and the most common words from macbeth is macb and haue. These makes sense as they are the main charater of the book. However looking deeper I realised there were still many similarities between the common words, so I wrote a new function that removes any overlapping words. From this, I'm able to get the most common words from the two plays that are not in the other play. This showed lot more interesting findinds such as the most common words from Hamlet excluding the charater names are hor, qu, and laer, whereas it is rosse, banquo and lenox for Macbeth. These words are not commonly seen in modern English, and may be from the shakespearean times. 

I also performed sentiment analysis for the two plays. The score is {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0} for both plays. This is very wierd as it means all the words have a neu rating. Lastly,the fuzz ratio analysis was not able to show a result.

I do believe I can do better in my word analysis part where I compared the similar and most frequent words. This is because my results are based on the most frequent words from the two books in a given range, and when I tried to look for unique words, it resulted in only a few words, so adding the stopwords was definitly a good idea. That being said, the data cleaning part could be improved as well. Just removing the stopwords is not enough for the two plays. because the plays are written in old English, there are still many mistakes and miss translations. Lots of the common words that showd up doesn't make sense. Next I think my sentiment analysis do not show a solid result. It may be on my part that my code did not successfully run, but from the results I can only tell that the words are neu. without neg and pos or compound. Lastly, I also learned that the fuzz analysis comparing the ratio of the two texts with similarities is not the best choice for this type of analysis. This is because I tried to run the code multiple times, and after many debugging I realized that this method takes a very long time to process, and even waiting over an houor in the end I was not able to get a result. 

